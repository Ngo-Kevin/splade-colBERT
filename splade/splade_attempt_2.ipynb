{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/final_project/splade-colBERT/splade'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just testing inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# !pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install omegaconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjammond\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving 0 files to the new cache system\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b51ce37a61048d0b691a80023e2a0f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "from splade.models.transformer_rep import Splade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# set the dir for trained weights\n",
    "\n",
    "##### v2\n",
    "# model_type_or_dir = \"weights/splade_max\"\n",
    "# model_type_or_dir = \"weights/distilsplade_max\"\n",
    "\n",
    "### v2bis, directly download from Hugging Face\n",
    "# model_type_or_dir = \"naver/splade-cocondenser-selfdistil\"\n",
    "model_type_or_dir = \"naver/splade-cocondenser-ensembledistil\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# loading model and tokenizer\n",
    "\n",
    "model = Splade(model_type_or_dir, agg=\"max\")\n",
    "model.eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_type_or_dir)\n",
    "reverse_voc = {v: k for k, v in tokenizer.vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# example document from MS MARCO passage collection (doc_id = 8003157)\n",
    "\n",
    "doc = \"Glass and Thermal Stress. Thermal Stress is created when one area of a glass pane gets hotter than an adjacent area. If the stress is too great then the glass will crack. The stress level at which the glass will break is governed by several factors.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of actual dimensions:  126\n",
      "SPLADE BOW rep:\n",
      " [('stress', 2.25), ('glass', 2.23), ('thermal', 2.18), ('glasses', 1.65), ('pan', 1.62), ('heat', 1.56), ('stressed', 1.42), ('crack', 1.31), ('break', 1.12), ('cracked', 1.1), ('hot', 0.93), ('created', 0.9), ('factors', 0.81), ('broken', 0.73), ('caused', 0.71), ('too', 0.71), ('damage', 0.69), ('if', 0.68), ('hotter', 0.65), ('governed', 0.61), ('heating', 0.59), ('temperature', 0.59), ('adjacent', 0.59), ('cause', 0.58), ('effect', 0.57), ('fracture', 0.56), ('bradford', 0.55), ('strain', 0.53), ('hammer', 0.51), ('brian', 0.48), ('error', 0.47), ('windows', 0.45), ('will', 0.45), ('reaction', 0.42), ('create', 0.42), ('windshield', 0.41), ('heated', 0.41), ('factor', 0.4), ('cracking', 0.39), ('failure', 0.38), ('mechanical', 0.38), ('when', 0.38), ('formed', 0.38), ('bolt', 0.38), ('mechanism', 0.37), ('warm', 0.37), ('areas', 0.36), ('area', 0.36), ('energy', 0.34), ('disorder', 0.33), ('barry', 0.33), ('shock', 0.32), ('determined', 0.32), ('gage', 0.32), ('sash', 0.31), ('theory', 0.31), ('level', 0.31), ('resistant', 0.31), ('brake', 0.3), ('window', 0.3), ('crash', 0.3), ('hazard', 0.29), ('##ink', 0.27), ('ceramic', 0.27), ('storm', 0.25), ('problem', 0.25), ('issue', 0.24), ('impact', 0.24), ('fridge', 0.24), ('injury', 0.23), ('ross', 0.22), ('causes', 0.22), ('affect', 0.21), ('pressure', 0.21), ('fatigue', 0.21), ('leak', 0.21), ('eye', 0.2), ('frank', 0.2), ('cool', 0.2), ('might', 0.19), ('gravity', 0.18), ('ray', 0.18), ('static', 0.18), ('collapse', 0.18), ('physics', 0.18), ('wave', 0.18), ('reflection', 0.17), ('parker', 0.17), ('strike', 0.17), ('hottest', 0.17), ('burst', 0.16), ('chance', 0.16), ('burn', 0.14), ('rubbing', 0.14), ('interference', 0.14), ('bailey', 0.13), ('vibration', 0.12), ('gilbert', 0.12), ('produced', 0.12), ('rock', 0.12), ('warmer', 0.11), ('get', 0.11), ('drink', 0.11), ('fireplace', 0.11), ('ruin', 0.1), ('brittle', 0.1), ('fragment', 0.1), ('stumble', 0.09), ('formation', 0.09), ('shatter', 0.08), ('great', 0.08), ('friction', 0.08), ('flash', 0.07), ('cracks', 0.07), ('levels', 0.07), ('smash', 0.04), ('fail', 0.04), ('fra', 0.04), ('##glass', 0.03), ('variables', 0.03), ('because', 0.02), ('knock', 0.02), ('sun', 0.02), ('crush', 0.01), ('##e', 0.01), ('anger', 0.01)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "# now compute the document representation\n",
    "with torch.no_grad():\n",
    "    doc_rep = model(d_kwargs=tokenizer(doc, return_tensors=\"pt\"))[\"d_rep\"].squeeze()  # (sparse) doc rep in voc space, shape (30522,)\n",
    "\n",
    "# get the number of non-zero dimensions in the rep:\n",
    "col = torch.nonzero(doc_rep).squeeze().cpu().tolist()\n",
    "print(\"number of actual dimensions: \", len(col))\n",
    "\n",
    "# now let's inspect the bow representation:\n",
    "weights = doc_rep[col].cpu().tolist()\n",
    "d = {k: v for k, v in zip(col, weights)}\n",
    "sorted_d = {k: v for k, v in sorted(d.items(), key=lambda item: item[1], reverse=True)}\n",
    "bow_rep = []\n",
    "for k, v in sorted_d.items():\n",
    "    bow_rep.append((reverse_voc[k], round(v, 2)))\n",
    "print(\"SPLADE BOW rep:\\n\", bow_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to run splade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE               \u001b[0m\u001b[01;34mdata\u001b[0m/                   inference_splade.ipynb  \u001b[01;34mweights\u001b[0m/\n",
      "README.md             data.tar.gz             setup.py\n",
      "conda_splade_env.yml  \u001b[01;34mefficient_splade_pisa\u001b[0m/  \u001b[01;34msplade\u001b[0m/\n",
      "\u001b[01;34mconf\u001b[0m/                 \u001b[01;34mimages\u001b[0m/                 splade_attempt_2.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '..\\': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "ls ..\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "marco_path = '..\\splade\\data\\msmarco'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!cd \"/home/jupyter/final_project/splade-colBERT/splade\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/final_project/splade-colBERT/splade\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dataset = {'D_COLLECTION_PATH': 'data/toy_data/val_collection', 'Q_COLLECTION_PATH': 'data/toy_data/val_queries', 'QREL_PATH': 'data/toy_data/qrel/qrel.json', 'TOP_K': 20}, 'COLLECTION_PATH': 'data/toy_data/full_collection', 'Q_COLLECTION_PATH': ['data/toy_data/dev_queries'], 'EVAL_QREL_PATH': ['data/toy_data/qrel/qrel.json'], 'flops_queries': 'data/toy_data/dev_queries'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hydra'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1396/4160079040.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msplade\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m config = {'config': {'lr': 2e-05, 'seed': 123, 'gradient_accumulation_steps': 1, 'weight_decay': 0.01, 'validation_metrics': ['MRR@10', 'recall@100', 'recall@200', 'recall@500'], 'pretrained_no_yamlconfig': False, 'nb_iterations': 10, 'train_batch_size': 6, 'eval_batch_size': 8, 'index_retrieve_batch_size': 6, 'record_frequency': 3, 'train_monitoring_freq':\n\u001b[1;32m      4\u001b[0m     2, 'warmup_steps': 5, 'max_length': 10, 'fp16': False, 'augment_pairs': 'in_batch_negatives', 'matching_type': 'splade', 'monitoring_ckpt': 'loss', 'loss': 'InBatchPairwiseNLL', 'regularizer': {'FLOPS': {'lambda_q': 0.0005, 'lambda_d': 0.0003, 'T': 3, 'targeted_rep': 'rep', 'reg': 'FLOPS'}}, 'tokenizer_type': 'distilbert-base-uncased', 'top_k': 5, 'threshold': 0.4, 'eval_metric': [['mrr_10', 'recall']], 'checkpoint_dir': 'data/msmarco', 'index_dir': '???', 'out_dir': '???'}, 'data': {'type': 'triplets', 'TRAIN_DATA_DIR': 'data/toy_data/triplets', 'VALIDATION_SIZE_FOR_LOSS': 20, 'VALIDATION_FULL_RANKING': {'D_COLLECTION_PATH': 'data/toy_data/val_collection', 'Q_COLLECTION_PATH': 'data/toy_data/val_queries', 'QREL_PATH': 'data/toy_data/qrel/qrel.json', 'TOP_K': 20}, 'COLLECTION_PATH': 'data/toy_data/full_collection', 'Q_COLLECTION_PATH': ['data/toy_data/dev_queries'], 'EVAL_QREL_PATH': ['data/toy_data/qrel/qrel.json'], 'flops_queries': 'data/toy_data/dev_queries'}, 'init_dict': {'model_type_or_dir': 'distilbert-base-uncased', 'model_type_or_dir_q': None, 'freeze_d_model': 0, 'agg': 'max', 'fp16': False}}\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/final_project/splade-colBERT/splade/splade/all.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhydra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0momegaconf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDictConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCONFIG_CHOICE\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONFIG_PATH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mflops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hydra'"
     ]
    }
   ],
   "source": [
    "from splade import all\n",
    "\n",
    "config = {'config': {'lr': 2e-05, 'seed': 123, 'gradient_accumulation_steps': 1, 'weight_decay': 0.01, 'validation_metrics': ['MRR@10', 'recall@100', 'recall@200', 'recall@500'], 'pretrained_no_yamlconfig': False, 'nb_iterations': 10, 'train_batch_size': 6, 'eval_batch_size': 8, 'index_retrieve_batch_size': 6, 'record_frequency': 3, 'train_monitoring_freq':\n",
    "    2, 'warmup_steps': 5, 'max_length': 10, 'fp16': False, 'augment_pairs': 'in_batch_negatives', 'matching_type': 'splade', 'monitoring_ckpt': 'loss', 'loss': 'InBatchPairwiseNLL', 'regularizer': {'FLOPS': {'lambda_q': 0.0005, 'lambda_d': 0.0003, 'T': 3, 'targeted_rep': 'rep', 'reg': 'FLOPS'}}, 'tokenizer_type': 'distilbert-base-uncased', 'top_k': 5, 'threshold': 0.4, 'eval_metric': [['mrr_10', 'recall']], 'checkpoint_dir': 'data/msmarco', 'index_dir': '???', 'out_dir': '???'}, 'data': {'type': 'triplets', 'TRAIN_DATA_DIR': 'data/toy_data/triplets', 'VALIDATION_SIZE_FOR_LOSS': 20, 'VALIDATION_FULL_RANKING': {'D_COLLECTION_PATH': 'data/toy_data/val_collection', 'Q_COLLECTION_PATH': 'data/toy_data/val_queries', 'QREL_PATH': 'data/toy_data/qrel/qrel.json', 'TOP_K': 20}, 'COLLECTION_PATH': 'data/toy_data/full_collection', 'Q_COLLECTION_PATH': ['data/toy_data/dev_queries'], 'EVAL_QREL_PATH': ['data/toy_data/qrel/qrel.json'], 'flops_queries': 'data/toy_data/dev_queries'}, 'init_dict': {'model_type_or_dir': 'distilbert-base-uncased', 'model_type_or_dir_q': None, 'freeze_d_model': 0, 'agg': 'max', 'fp16': False}}\n",
    "\n",
    "\n",
    "all.train_index_retrieve(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\jammo\\\\DataspellProjects\\\\capstone\\\\new_capstone_dir\\\\splade-colBERT\\\\splade'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid input. Supports one of [dict,list,DictConfig,ListConfig,dataclass,dataclass instance,attr class,attr class instance]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# from utils import utils\u001b[39;00m\n\u001b[0;32m      4\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mconf\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mconfig_splade++_cocondenser_ensembledistil_monogpu.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_initialize_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\DataspellProjects\\capstone\\new_capstone_dir\\splade-colBERT\\splade\\splade\\utils\\utils.py:112\u001b[0m, in \u001b[0;36mget_initialize_config\u001b[1;34m(exp_dict, train)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_initialize_config\u001b[39m(exp_dict: DictConfig, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# delay import to reduce dependencies\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhydra\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hydra_chdir\n\u001b[1;32m--> 112\u001b[0m     \u001b[43mhydra_chdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m     exp_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m exp_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    114\u001b[0m     config \u001b[38;5;241m=\u001b[39m exp_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\DataspellProjects\\capstone\\new_capstone_dir\\splade-colBERT\\splade\\splade\\utils\\hydra.py:8\u001b[0m, in \u001b[0;36mhydra_chdir\u001b[1;34m(exp_dict)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhydra_chdir\u001b[39m(exp_dict):\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mOmegaConf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_yaml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_dict\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m         os\u001b[38;5;241m.\u001b[39mchdir(get_original_cwd())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\omegaconf\\omegaconf.py:746\u001b[0m, in \u001b[0;36mOmegaConf.to_yaml\u001b[1;34m(cfg, resolve, sort_keys)\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_yaml\u001b[39m(cfg: Any, \u001b[38;5;241m*\u001b[39m, resolve: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, sort_keys: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;124;03m    returns a yaml dump of this config object.\u001b[39;00m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;124;03m    :param cfg: Config object, Structured Config type or instance\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;124;03m    :return: A string containing the yaml representation.\u001b[39;00m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 746\u001b[0m     cfg \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_container\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m     container \u001b[38;5;241m=\u001b[39m OmegaConf\u001b[38;5;241m.\u001b[39mto_container(cfg, resolve\u001b[38;5;241m=\u001b[39mresolve, enum_to_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m yaml\u001b[38;5;241m.\u001b[39mdump(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    749\u001b[0m         container,\n\u001b[0;32m    750\u001b[0m         default_flow_style\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    753\u001b[0m         Dumper\u001b[38;5;241m=\u001b[39mget_omega_conf_dumper(),\n\u001b[0;32m    754\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\omegaconf\\_utils.py:957\u001b[0m, in \u001b[0;36m_ensure_container\u001b[1;34m(target, flags)\u001b[0m\n\u001b[0;32m    955\u001b[0m     target \u001b[38;5;241m=\u001b[39m OmegaConf\u001b[38;5;241m.\u001b[39mstructured(target, flags\u001b[38;5;241m=\u001b[39mflags)\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OmegaConf\u001b[38;5;241m.\u001b[39mis_config(target):\n\u001b[1;32m--> 957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input. Supports one of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[dict,list,DictConfig,ListConfig,dataclass,dataclass instance,attr class,attr class instance]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m     )\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m target\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid input. Supports one of [dict,list,DictConfig,ListConfig,dataclass,dataclass instance,attr class,attr class instance]"
     ]
    }
   ],
   "source": [
    "from splade.utils import utils\n",
    "\n",
    "config = \"..\\conf\\config_splade++_cocondenser_ensembledistil_monogpu.yaml\"\n",
    "\n",
    "utils.get_initialize_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mRun\u001b[49m()\u001b[38;5;241m.\u001b[39mcontext(RunConfig(nranks\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, experiment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsmarco\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m      2\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m      3\u001b[0m         triples\u001b[38;5;241m=\u001b[39m  \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmsmarco\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msplade_triplets\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m         queries\u001b[38;5;241m=\u001b[39m  \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmsmarco\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrain_queries\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mqueries\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mraw.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m         collection\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmsmarco\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfull_collection\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mraw.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m      7\u001b[0m     )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Run' is not defined"
     ]
    }
   ],
   "source": [
    "# with Run().context(RunConfig(nranks=1, experiment=\"msmarco\")):\n",
    "#     trainer = Trainer(\n",
    "#         triples=  r\"..\\data\\msmarco\\splade_triplets\",\n",
    "#         queries=  r\"..\\data\\msmarco\\train_queries\\queries\\raw.tsv\",\n",
    "#         collection= r\"..\\data\\msmarco\\full_collection\\raw.tsv\",\n",
    "#         config=config,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# model =\n",
    "# iterations = 1\n",
    "# loss =\n",
    "# optimizer =\n",
    "# config = \"..\\conf\\config_splade++_cocondenser_ensembledistil_monogpu.yaml\"\n",
    "# scheduler =\n",
    "# train_loader =\n",
    "# val_loss_loader =\n",
    "# val_evaluator +\n",
    "# regularizer =\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%bash\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is C85C-4698\n",
      "\n",
      " Directory of C:\\Users\\jammo\\DataspellProjects\\capstone\\new_capstone_dir\\splade-colBERT\\splade\n",
      "\n",
      "10/02/2022  01:35 PM    <DIR>          .\n",
      "10/02/2022  01:35 PM    <DIR>          ..\n",
      "10/01/2022  11:52 AM    <DIR>          .ipynb_checkpoints\n",
      "09/26/2022  05:45 PM             6,799 conda_splade_env.yml\n",
      "10/02/2022  12:10 PM    <DIR>          conf\n",
      "10/01/2022  12:23 PM    <DIR>          data\n",
      "09/26/2022  05:45 PM    <DIR>          efficient_splade_pisa\n",
      "09/26/2022  05:45 PM    <DIR>          images\n",
      "10/02/2022  12:33 PM             9,352 inference_splade.ipynb\n",
      "09/26/2022  05:45 PM            33,764 LICENSE\n",
      "09/26/2022  05:45 PM            17,307 README.md\n",
      "09/26/2022  05:45 PM               743 setup.py\n",
      "10/01/2022  10:34 AM    <DIR>          splade\n",
      "10/02/2022  01:35 PM            17,556 splade_attempt_2.ipynb\n",
      "09/26/2022  05:45 PM    <DIR>          weights\n",
      "               6 File(s)         85,521 bytes\n",
      "               9 Dir(s)  56,088,412,160 bytes free\n"
     ]
    }
   ],
   "source": [
    "# trainer = SiameseTransformerTrainer(model=model, iterations=iterations, loss=loss, optimizer=optimizer,\n",
    "#                                     config=config, scheduler=scheduler,\n",
    "#                                     train_loader=train_loader, validation_loss_loader=val_loss_loader,\n",
    "#                                     validation_evaluator=val_evaluator,\n",
    "#                                     regularizer=regularizer)\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is C85C-4698\n",
      "\n",
      " Directory of C:\\Users\\jammo\\DataspellProjects\\capstone\\new_capstone_dir\\splade-colBERT\\splade\\data\\msmarco\\full_collection\n",
      "\n",
      "10/01/2022  12:23 PM    <DIR>          .\n",
      "10/01/2022  12:23 PM    <DIR>          ..\n",
      "04/20/2022  05:52 AM                 0 .skeleton\n",
      "04/20/2022  05:56 AM     3,047,524,442 raw.tsv\n",
      "               2 File(s)  3,047,524,442 bytes\n",
      "               2 Dir(s)  56,086,917,120 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls data\\msmarco\\full_collection\\raw.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
